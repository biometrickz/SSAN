{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets preparation. 1. Creating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6680d6e1-d4a3-45da-b138-252c1803b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50f6d12-156a-44c7-b2a7-7664e393588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels_csv(dirr):\n",
    "    train_files = os.listdir(dirr)\n",
    "    df = pd.DataFrame(columns=[\"label\", \"fname\"])\n",
    "    df[\"fname\"] = train_files\n",
    "    if 'spoof' in dirr:\n",
    "        df[\"label\"] = 1\n",
    "    else:\n",
    "        df[\"label\"] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014309c0-9800-42e5-849b-5e5ce36af310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirr1 = \"/media/yeldar/C4EBBAE4D0BBE84F/0.0_padded_liveness_dataset/val/1_300x300/live\"\n",
    "dirr2 = \"/media/yeldar/C4EBBAE4D0BBE84F/0.0_padded_liveness_dataset/val/1_300x300/spoof\"\n",
    "df = pd.concat([generate_labels_csv(dirr1), generate_labels_csv(dirr2)])\n",
    "df.to_csv(\"/media/yeldar/C4EBBAE4D0BBE84F/0.0_padded_liveness_dataset/val/val_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30467"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merging live and spoof images into one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_folders(dir1, dir2, dest):\n",
    "    for fl in os.listdir(dir1):\n",
    "        cur_p = os.path.join(dir1, fl)\n",
    "        dst_p = os.path.join(dest, fl)\n",
    "        os.rename(cur_p, dst_p)\n",
    "    for fl2 in os.listdir(dir2):\n",
    "        cur_p = os.path.join(dir2, fl2)\n",
    "        dst_p = os.path.join(dest, fl2)\n",
    "        os.rename(cur_p, dst_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirr1 = \"/media/yeldar/C4EBBAE4D0BBE84F/0.0_padded_liveness_dataset/val/1_300x300/live\"\n",
    "dirr2 = \"/media/yeldar/C4EBBAE4D0BBE84F/0.0_padded_liveness_dataset/val/1_300x300/spoof\"\n",
    "dest = \"/media/yeldar/C4EBBAE4D0BBE84F/0.0_padded_liveness_dataset/Val_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_folders(dirr1, dirr2, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_info(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.root_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid3_3_09_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>frame4vid2_2_05_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid3_3_10_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid3_2_10_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid2_3_06_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_3_02_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_2_02_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_2_02_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_3_02_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_2_04_3.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1                      2\n",
       "0    0  frame0vid3_3_09_1.jpg\n",
       "1    0  frame4vid2_2_05_1.jpg\n",
       "2    0  frame0vid3_3_10_1.jpg\n",
       "3    0  frame0vid3_2_10_1.jpg\n",
       "4    0  frame0vid2_3_06_1.jpg\n",
       "..  ..                    ...\n",
       "220  1  frame0vid1_3_02_4.jpg\n",
       "221  1  frame0vid1_2_02_4.jpg\n",
       "222  1  frame0vid1_2_02_5.jpg\n",
       "223  1  frame0vid1_3_02_5.jpg\n",
       "224  1  frame0vid1_2_04_3.jpg\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = \"/home/yeldar/Documents/Liveness/datasets/sample_dataset\"\n",
    "CUSTOM_Train = dataset_info()\n",
    "CUSTOM_Train.root_dir = os.path.join(image_dir, \"Custom\")\n",
    "data_dir = CUSTOM_Train.root_dir\n",
    "root_dir = os.path.join(data_dir, \"Train_files\")\n",
    "info_list = os.path.join(data_dir, \"train_list.csv\")\n",
    "labels = pd.read_csv(info_list, delimiter=\",\", header=None).drop([0], axis=1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from scrfd.scrfd import SCRFD \n",
    "import warnings \n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== SCRFD-500m onnx Face Detector loaded. ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeldar/anaconda3/envs/dot/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:53: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\"Specified provider '{}' is not in available provider names.\"\n"
     ]
    }
   ],
   "source": [
    "face_detector = SCRFD(model_file='./scrfd/scrfd_500m_bnkps.onnx')\n",
    "face_detector.prepare(1)\n",
    "print(\"====== SCRFD-500m onnx Face Detector loaded. ======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_face_detection(image, face_detector):\n",
    "    \n",
    "    bboxes, kpss = face_detector.detect(image, input_size=(640, 640))\n",
    "    bboxes_b = bboxes[:, 0:4]\n",
    "    bboxes_b = bboxes_b.astype('int32')\n",
    "    #  postprocess bounding boxes\n",
    "    x, y, w, h = [[box[0], box[1], box[2] - box[0], box[3] - box[1]]  for box in bboxes_b][0]\n",
    "    # face = image[y:y+h, x:x+w]\n",
    "    return x, y, w, h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame0vid5_3_10_1.jpg\n",
      "frame0vid1_2_02_1.jpg\n",
      "frame0vid1_3_06_4.jpg\n",
      "frame0vid1_1_04_2.jpg\n",
      "frame0vid1_3_02_1.jpg\n",
      "frame0vid1_1_07_4.jpg\n",
      "frame0vid1_3_09_1.jpg\n",
      "frame0vid1_2_05_5.jpg\n",
      "frame0vid3_1_06_2.jpg\n",
      "frame0vid1_1_05_4.jpg\n",
      "frame0vid5_1_09_1.jpg\n",
      "frame1vid1_3_10_1.jpg\n",
      "frame0vid2_3_04_2.jpg\n",
      "frame0vid1_2_07_3.jpg\n",
      "frame0vid1_2_06_3.jpg\n",
      "frame0vid2_2_06_1.jpg\n",
      "frame3vid5_3_05_1.jpg\n",
      "frame0vid2_3_03_4.jpg\n",
      "frame0vid1_2_02_5.jpg\n",
      "frame1vid1_2_09_1.jpg\n",
      "frame0vid3_3_03_2.jpg\n",
      "frame0vid3_3_09_1.jpg\n",
      "frame0vid6_2_09_1.jpg\n",
      "frame0vid1_2_03_1.jpg\n",
      "frame0vid2_3_05_5.jpg\n",
      "frame0vid4_3_06_1.jpg\n",
      "frame4vid1_1_05_1.jpg\n",
      "frame0vid1_2_08_1.jpg\n",
      "frame0vid1_3_06_1.jpg\n",
      "frame0vid1_3_06_3.jpg\n",
      "frame0vid2_2_05_2.jpg\n",
      "frame0vid1_3_06_2.jpg\n",
      "frame0vid3_1_10_1.jpg\n",
      "frame0vid2_2_03_2.jpg\n",
      "frame0vid3_1_08_4.jpg\n",
      "frame0vid2_2_07_4.jpg\n",
      "frame0vid1_1_05_5.jpg\n",
      "frame0vid1_2_04_2.jpg\n",
      "frame1vid2_1_10_1.jpg\n",
      "frame1vid1_3_07_1.jpg\n",
      "frame4vid2_2_05_1.jpg\n",
      "frame0vid4_1_10_1.jpg\n",
      "frame0vid1_2_08_5.jpg\n",
      "frame0vid2_3_04_3.jpg\n",
      "frame0vid5_2_09_1.jpg\n",
      "frame0vid4_3_03_1.jpg\n",
      "frame0vid1_2_05_3.jpg\n",
      "frame0vid1_1_02_2.jpg\n",
      "frame0vid6_2_08_1.jpg\n",
      "frame0vid4_1_06_1.jpg\n",
      "frame0vid1_2_06_5.jpg\n",
      "frame0vid3_3_06_1.jpg\n",
      "frame0vid1_1_06_2.jpg\n",
      "frame0vid1_2_08_4.jpg\n",
      "frame0vid3_1_08_5.jpg\n",
      "frame0vid2_1_08_1.jpg\n",
      "frame3vid4_2_05_1.jpg\n",
      "frame0vid1_1_08_1.jpg\n",
      "frame0vid1_1_07_1.jpg\n",
      "frame0vid5_1_07_1.jpg\n",
      "frame0vid3_3_10_1.jpg\n",
      "frame0vid2_3_07_2.jpg\n",
      "frame0vid2_2_06_2.jpg\n",
      "frame0vid6_3_08_1.jpg\n",
      "frame1vid2_1_09_1.jpg\n",
      "frame0vid3_1_04_2.jpg\n",
      "frame0vid3_3_07_1.jpg\n",
      "frame0vid3_3_03_1.jpg\n",
      "frame0vid1_2_10_1.jpg\n",
      "frame3vid4_3_05_1.jpg\n",
      "frame0vid1_2_07_1.jpg\n",
      "frame0vid1_1_08_4.jpg\n",
      "frame0vid2_2_08_5.jpg\n",
      "frame0vid1_2_06_2.jpg\n",
      "frame4vid1_2_05_1.jpg\n",
      "frame0vid1_1_03_5.jpg\n",
      "frame0vid1_2_07_5.jpg\n",
      "frame0vid2_3_02_1.jpg\n",
      "frame0vid2_3_06_5.jpg\n",
      "frame0vid2_2_02_1.jpg\n",
      "frame0vid1_3_04_2.jpg\n",
      "frame0vid2_2_04_4.jpg\n",
      "frame0vid2_3_07_5.jpg\n",
      "frame0vid5_3_09_1.jpg\n",
      "frame3vid5_2_05_1.jpg\n",
      "frame0vid2_2_08_4.jpg\n",
      "frame0vid4_1_07_1.jpg\n",
      "frame0vid1_1_10_1.jpg\n",
      "frame0vid1_2_02_4.jpg\n",
      "depth\n",
      "frame0vid1_3_08_4.jpg\n",
      "frame0vid1_2_07_4.jpg\n",
      "frame0vid1_1_05_2.jpg\n",
      "frame0vid3_1_09_1.jpg\n",
      "frame0vid2_2_05_3.jpg\n",
      "frame0vid4_3_09_1.jpg\n",
      "frame1vid1_1_09_1.jpg\n",
      "frame0vid2_3_06_1.jpg\n",
      "frame0vid1_3_03_1.jpg\n",
      "frame0vid1_1_08_5.jpg\n",
      "frame0vid2_3_06_2.jpg\n",
      "frame0vid2_2_05_4.jpg\n",
      "frame0vid1_2_06_4.jpg\n",
      "frame1vid2_3_10_1.jpg\n",
      "frame0vid1_3_02_5.jpg\n",
      "frame0vid1_2_05_2.jpg\n",
      "frame0vid5_2_10_1.jpg\n",
      "frame0vid1_1_02_3.jpg\n",
      "frame0vid2_2_03_4.jpg\n",
      "frame0vid1_1_09_1.jpg\n",
      "frame0vid2_2_05_5.jpg\n",
      "frame0vid3_1_06_3.jpg\n",
      "frame1vid2_2_10_1.jpg\n",
      "frame0vid1_1_03_2.jpg\n",
      "frame1vid1_1_07_1.jpg\n",
      "frame0vid1_3_07_1.jpg\n",
      "frame0vid1_1_04_5.jpg\n",
      "frame1vid1_3_08_1.jpg\n",
      "frame1vid2_2_09_1.jpg\n",
      "frame0vid6_3_09_1.jpg\n",
      "frame0vid1_1_07_5.jpg\n",
      "frame0vid1_2_04_5.jpg\n",
      "frame0vid1_2_03_4.jpg\n",
      "frame0vid1_1_04_1.jpg\n",
      "frame0vid2_3_08_4.jpg\n",
      "frame0vid2_2_03_1.jpg\n",
      "frame0vid2_2_07_3.jpg\n",
      "frame0vid1_1_03_4.jpg\n",
      "frame0vid3_1_05_4.jpg\n",
      "frame0vid1_2_07_2.jpg\n",
      "frame0vid5_1_03_1.jpg\n",
      "frame0vid1_2_04_3.jpg\n",
      "frame0vid1_3_02_2.jpg\n",
      "frame0vid1_2_03_5.jpg\n",
      "frame1vid1_2_07_1.jpg\n",
      "frame0vid1_1_06_5.jpg\n",
      "frame0vid1_1_06_3.jpg\n",
      "frame0vid6_3_07_1.jpg\n",
      "frame0vid6_1_10_1.jpg\n",
      "frame0vid2_1_02_1.jpg\n",
      "frame0vid1_1_06_4.jpg\n",
      "frame0vid2_3_05_2.jpg\n",
      "frame0vid1_3_05_4.jpg\n",
      "frame0vid2_2_04_2.jpg\n",
      "frame0vid3_2_10_1.jpg\n",
      "frame0vid5_2_06_1.jpg\n",
      "frame1vid1_2_08_1.jpg\n",
      "frame0vid2_3_06_4.jpg\n",
      "frame0vid4_2_09_1.jpg\n",
      "frame0vid1_3_04_1.jpg\n",
      "frame0vid4_2_08_1.jpg\n",
      "frame0vid3_3_04_1.jpg\n",
      "frame0vid2_2_04_5.jpg\n",
      "frame0vid5_1_06_1.jpg\n",
      "frame0vid2_3_09_1.jpg\n",
      "frame0vid4_2_03_1.jpg\n",
      "frame0vid2_2_03_3.jpg\n",
      "frame0vid2_2_08_1.jpg\n",
      "frame0vid4_1_08_1.jpg\n",
      "frame0vid2_2_07_1.jpg\n",
      "frame0vid3_3_08_1.jpg\n",
      "frame0vid4_1_04_1.jpg\n",
      "frame0vid4_3_07_1.jpg\n",
      "frame0vid2_1_06_1.jpg\n",
      "frame0vid2_1_03_1.jpg\n",
      "frame0vid1_1_07_3.jpg\n",
      "frame0vid2_3_03_5.jpg\n",
      "frame0vid5_1_08_1.jpg\n",
      "frame0vid4_2_07_1.jpg\n",
      "frame0vid1_3_02_4.jpg\n",
      "frame0vid2_2_06_4.jpg\n",
      "frame0vid2_1_09_1.jpg\n",
      "frame0vid1_2_02_3.jpg\n",
      "frame0vid2_3_07_4.jpg\n",
      "frame0vid4_2_10_1.jpg\n",
      "frame0vid2_2_09_1.jpg\n",
      "frame4vid2_1_05_1.jpg\n",
      "frame0vid1_2_02_2.jpg\n",
      "frame0vid2_3_06_3.jpg\n",
      "frame0vid4_3_08_1.jpg\n",
      "frame1vid1_3_09_1.jpg\n",
      "frame4vid1_3_05_1.jpg\n",
      "frame0vid2_2_03_5.jpg\n",
      "frame0vid1_1_03_1.jpg\n",
      "frame0vid1_2_06_1.jpg\n",
      "frame0vid1_2_05_4.jpg\n",
      "frame0vid1_2_09_1.jpg\n",
      "frame0vid2_3_04_4.jpg\n",
      "frame0vid2_3_10_1.jpg\n",
      "frame0vid4_2_04_1.jpg\n",
      "frame0vid5_1_10_1.jpg\n",
      "frame0vid3_3_03_3.jpg\n",
      "frame0vid2_2_06_5.jpg\n",
      "frame0vid1_1_06_1.jpg\n",
      "frame0vid1_3_08_5.jpg\n",
      "frame0vid2_3_05_3.jpg\n",
      "frame0vid1_3_08_1.jpg\n",
      "frame0vid2_2_07_5.jpg\n",
      "frame0vid4_3_04_1.jpg\n",
      "frame0vid4_2_06_1.jpg\n",
      "frame0vid1_2_04_4.jpg\n",
      "frame0vid6_2_07_1.jpg\n",
      "frame0vid2_3_07_3.jpg\n",
      "frame0vid2_1_04_1.jpg\n",
      "frame0vid2_3_08_5.jpg\n",
      "frame0vid2_2_07_2.jpg\n",
      "frame0vid2_3_05_4.jpg\n",
      "frame0vid1_1_04_3.jpg\n",
      "frame0vid1_1_07_2.jpg\n",
      "frame0vid2_1_07_1.jpg\n",
      "frame0vid1_1_04_4.jpg\n",
      "frame0vid3_1_06_4.jpg\n",
      "frame0vid1_1_03_3.jpg\n",
      "frame0vid4_1_09_1.jpg\n",
      "frame0vid1_1_02_1.jpg\n",
      "frame0vid1_1_02_4.jpg\n",
      "frame0vid2_3_04_5.jpg\n",
      "frame0vid1_3_10_1.jpg\n",
      "frame0vid2_2_04_3.jpg\n",
      "frame0vid2_2_06_3.jpg\n",
      "frame0vid1_2_04_1.jpg\n",
      "frame0vid1_1_02_5.jpg\n",
      "frame1vid1_1_08_1.jpg\n",
      "frame0vid1_1_05_3.jpg\n",
      "frame0vid4_1_03_1.jpg\n",
      "frame3vid5_1_05_1.jpg\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"/home/yeldar/Documents/Liveness/datasets/sample_dataset/Train_files/\"\n",
    "for img_n in os.listdir(img_dir):\n",
    "    img_path = os.path.join(img_dir, img_n)\n",
    "     x, y, w, h = get_bbox_face_detection(img_path, face_detector)\n",
    "        image_x = cv2.resize(crop_face_from_scene(image_x_temp, [y, x, w, h], face_scale), (self.img_size, self.img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "img_dir = \"/home/yeldar/Documents/Liveness/datasets/sample_dataset/\"\n",
    "f_path = os.path.join(img_dir, \"Train.pickle\")\n",
    "with open(f_path, 'rb') as handle:\n",
    "    bboxes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame0vid5_3_10_1.jpg': [445, 353, 400, 502],\n",
       " 'frame0vid1_2_02_1.jpg': [352, 341, 387, 547],\n",
       " 'frame0vid1_3_06_4.jpg': [256, 359, 394, 572],\n",
       " 'frame0vid1_1_04_2.jpg': [687, 301, 503, 660],\n",
       " 'frame0vid1_3_02_1.jpg': [423, 378, 413, 546],\n",
       " 'frame0vid1_1_07_4.jpg': [632, 318, 435, 597],\n",
       " 'frame0vid1_3_09_1.jpg': [226, 338, 413, 560],\n",
       " 'frame0vid1_2_05_5.jpg': [223, 265, 423, 521],\n",
       " 'frame0vid3_1_06_2.jpg': [619, 313, 414, 584],\n",
       " 'frame0vid1_1_05_4.jpg': [614, 274, 489, 629],\n",
       " 'frame0vid5_1_09_1.jpg': [737, 392, 401, 532],\n",
       " 'frame1vid1_3_10_1.jpg': [528, 375, 391, 489],\n",
       " 'frame0vid2_3_04_2.jpg': [317, 344, 424, 579],\n",
       " 'frame0vid1_2_07_3.jpg': [171, 274, 455, 634],\n",
       " 'frame0vid1_2_06_3.jpg': [223, 277, 388, 557],\n",
       " 'frame0vid2_2_06_1.jpg': [432, 348, 379, 544],\n",
       " 'frame3vid5_3_05_1.jpg': [444, 364, 412, 553],\n",
       " 'frame0vid2_3_03_4.jpg': [558, 399, 368, 496],\n",
       " 'frame0vid1_2_02_5.jpg': [322, 317, 381, 481],\n",
       " 'frame1vid1_2_09_1.jpg': [214, 361, 381, 513],\n",
       " 'frame0vid3_3_03_2.jpg': [469, 446, 403, 552],\n",
       " 'frame0vid3_3_09_1.jpg': [460, 331, 602, 797],\n",
       " 'frame0vid6_2_09_1.jpg': [182, 317, 482, 641],\n",
       " 'frame0vid1_2_03_1.jpg': [390, 360, 390, 557],\n",
       " 'frame0vid2_3_05_5.jpg': [358, 316, 420, 536],\n",
       " 'frame0vid4_3_06_1.jpg': [320, 376, 391, 606],\n",
       " 'frame4vid1_1_05_1.jpg': [642, 348, 394, 513],\n",
       " 'frame0vid1_2_08_1.jpg': [186, 364, 391, 549],\n",
       " 'frame0vid1_3_06_1.jpg': [380, 385, 350, 543],\n",
       " 'frame0vid1_3_06_3.jpg': [307, 334, 419, 612],\n",
       " 'frame0vid2_2_05_2.jpg': [423, 307, 419, 536],\n",
       " 'frame0vid1_3_06_2.jpg': [297, 347, 437, 626],\n",
       " 'frame0vid3_1_10_1.jpg': [510, 268, 656, 856],\n",
       " 'frame0vid2_2_03_2.jpg': [625, 340, 380, 524],\n",
       " 'frame0vid3_1_08_4.jpg': [467, 287, 510, 706],\n",
       " 'frame0vid2_2_07_4.jpg': [219, 265, 429, 620],\n",
       " 'frame0vid1_1_05_5.jpg': [511, 320, 506, 640],\n",
       " 'frame0vid1_2_04_2.jpg': [268, 223, 520, 708],\n",
       " 'frame1vid2_1_10_1.jpg': [576, 337, 465, 609],\n",
       " 'frame1vid1_3_07_1.jpg': [451, 365, 343, 482],\n",
       " 'frame4vid2_2_05_1.jpg': [187, 302, 446, 621],\n",
       " 'frame0vid4_1_10_1.jpg': [527, 306, 560, 714],\n",
       " 'frame0vid1_2_08_5.jpg': [92, 267, 463, 629],\n",
       " 'frame0vid2_3_04_3.jpg': [343, 366, 431, 612],\n",
       " 'frame0vid5_2_09_1.jpg': [329, 356, 371, 489],\n",
       " 'frame0vid4_3_03_1.jpg': [464, 368, 377, 520],\n",
       " 'frame0vid1_2_05_3.jpg': [396, 290, 420, 524],\n",
       " 'frame0vid1_1_02_2.jpg': [793, 299, 486, 605],\n",
       " 'frame0vid6_2_08_1.jpg': [237, 362, 404, 563],\n",
       " 'frame0vid4_1_06_1.jpg': [318, 355, 427, 648],\n",
       " 'frame0vid1_2_06_5.jpg': [362, 271, 424, 590],\n",
       " 'frame0vid3_3_06_1.jpg': [283, 332, 471, 682],\n",
       " 'frame0vid1_1_06_2.jpg': [738, 309, 453, 630],\n",
       " 'frame0vid1_2_08_4.jpg': [78, 199, 473, 654],\n",
       " 'frame0vid3_1_08_5.jpg': [466, 249, 521, 723],\n",
       " 'frame0vid2_1_08_1.jpg': [777, 358, 356, 495],\n",
       " 'frame3vid4_2_05_1.jpg': [241, 319, 434, 575],\n",
       " 'frame0vid1_1_08_1.jpg': [748, 373, 348, 470],\n",
       " 'frame0vid1_1_07_1.jpg': [697, 365, 391, 534],\n",
       " 'frame0vid5_1_07_1.jpg': [849, 335, 401, 542],\n",
       " 'frame0vid3_3_10_1.jpg': [288, 275, 529, 676],\n",
       " 'frame0vid2_3_07_2.jpg': [405, 342, 359, 501],\n",
       " 'frame0vid2_2_06_2.jpg': [268, 281, 373, 555],\n",
       " 'frame0vid6_3_08_1.jpg': [217, 374, 492, 692],\n",
       " 'frame1vid2_1_09_1.jpg': [696, 368, 414, 553],\n",
       " 'frame0vid3_1_04_2.jpg': [595, 216, 527, 693],\n",
       " 'frame0vid3_3_07_1.jpg': [261, 406, 562, 757],\n",
       " 'frame0vid3_3_03_1.jpg': [236, 295, 495, 697],\n",
       " 'frame0vid1_2_10_1.jpg': [333, 377, 380, 492],\n",
       " 'frame3vid4_3_05_1.jpg': [329, 338, 424, 571],\n",
       " 'frame0vid1_2_07_1.jpg': [308, 404, 393, 569],\n",
       " 'frame0vid1_1_08_4.jpg': [565, 278, 502, 695],\n",
       " 'frame0vid2_2_08_5.jpg': [190, 264, 426, 598],\n",
       " 'frame0vid1_2_06_2.jpg': [229, 295, 412, 603],\n",
       " 'frame4vid1_2_05_1.jpg': [207, 303, 451, 623],\n",
       " 'frame0vid1_1_03_5.jpg': [563, 381, 399, 549],\n",
       " 'frame0vid1_2_07_5.jpg': [156, 280, 442, 613],\n",
       " 'frame0vid2_3_02_1.jpg': [523, 342, 424, 560],\n",
       " 'frame0vid2_3_06_5.jpg': [240, 359, 380, 563],\n",
       " 'frame0vid2_2_02_1.jpg': [441, 365, 399, 553],\n",
       " 'frame0vid1_3_04_2.jpg': [327, 350, 440, 597],\n",
       " 'frame0vid2_2_04_4.jpg': [274, 249, 459, 660],\n",
       " 'frame0vid2_3_07_5.jpg': [394, 387, 339, 468],\n",
       " 'frame0vid5_3_09_1.jpg': [265, 324, 480, 651],\n",
       " 'frame3vid5_2_05_1.jpg': [369, 363, 402, 526],\n",
       " 'frame0vid2_2_08_4.jpg': [171, 265, 441, 625],\n",
       " 'frame0vid4_1_07_1.jpg': [820, 319, 519, 682],\n",
       " 'frame0vid1_1_10_1.jpg': [691, 348, 410, 523],\n",
       " 'frame0vid1_2_02_4.jpg': [318, 249, 392, 501],\n",
       " 'frame0vid1_3_08_4.jpg': [325, 308, 434, 627],\n",
       " 'frame0vid1_2_07_4.jpg': [135, 211, 458, 653],\n",
       " 'frame0vid1_1_05_2.jpg': [729, 245, 515, 652],\n",
       " 'frame0vid3_1_09_1.jpg': [658, 307, 569, 742],\n",
       " 'frame0vid2_2_05_3.jpg': [436, 368, 426, 536],\n",
       " 'frame0vid4_3_09_1.jpg': [322, 259, 457, 615],\n",
       " 'frame1vid1_1_09_1.jpg': [680, 340, 438, 588],\n",
       " 'frame0vid2_3_06_1.jpg': [267, 353, 396, 587],\n",
       " 'frame0vid1_3_03_1.jpg': [470, 358, 377, 534],\n",
       " 'frame0vid1_1_08_5.jpg': [485, 292, 509, 698],\n",
       " 'frame0vid2_3_06_2.jpg': [318, 363, 389, 581],\n",
       " 'frame0vid2_2_05_4.jpg': [301, 250, 420, 524],\n",
       " 'frame0vid1_2_06_4.jpg': [373, 217, 418, 610],\n",
       " 'frame1vid2_3_10_1.jpg': [377, 316, 425, 539],\n",
       " 'frame0vid1_3_02_5.jpg': [424, 342, 432, 573],\n",
       " 'frame0vid1_2_05_2.jpg': [403, 354, 424, 532],\n",
       " 'frame0vid5_2_10_1.jpg': [416, 392, 420, 549],\n",
       " 'frame0vid1_1_02_3.jpg': [705, 300, 446, 562],\n",
       " 'frame0vid2_2_03_4.jpg': [564, 305, 402, 541],\n",
       " 'frame0vid1_1_09_1.jpg': [684, 339, 438, 586],\n",
       " 'frame0vid2_2_05_5.jpg': [317, 261, 403, 500],\n",
       " 'frame0vid3_1_06_3.jpg': [797, 312, 418, 592],\n",
       " 'frame1vid2_2_10_1.jpg': [390, 352, 424, 547],\n",
       " 'frame0vid1_1_03_2.jpg': [796, 268, 418, 561],\n",
       " 'frame1vid1_1_07_1.jpg': [702, 366, 392, 530],\n",
       " 'frame0vid1_3_07_1.jpg': [452, 364, 345, 480],\n",
       " 'frame0vid1_1_04_5.jpg': [483, 315, 498, 656],\n",
       " 'frame1vid1_3_08_1.jpg': [305, 391, 354, 525],\n",
       " 'frame1vid2_2_09_1.jpg': [247, 385, 368, 486],\n",
       " 'frame0vid6_3_09_1.jpg': [386, 254, 553, 741],\n",
       " 'frame0vid1_1_07_5.jpg': [531, 327, 452, 603],\n",
       " 'frame0vid1_2_04_5.jpg': [201, 257, 481, 655],\n",
       " 'frame0vid1_2_03_4.jpg': [476, 259, 425, 585],\n",
       " 'frame0vid1_1_04_1.jpg': [622, 363, 430, 621],\n",
       " 'frame0vid2_3_08_4.jpg': [303, 313, 428, 623],\n",
       " 'frame0vid2_2_03_1.jpg': [238, 325, 409, 604],\n",
       " 'frame0vid2_2_07_3.jpg': [211, 334, 474, 688],\n",
       " 'frame0vid1_1_03_4.jpg': [660, 363, 398, 531],\n",
       " 'frame0vid3_1_05_4.jpg': [531, 280, 488, 626],\n",
       " 'frame0vid1_2_07_2.jpg': [171, 274, 455, 634],\n",
       " 'frame0vid5_1_03_1.jpg': [712, 328, 381, 532],\n",
       " 'frame0vid1_2_04_3.jpg': [273, 212, 493, 668],\n",
       " 'frame0vid1_3_02_2.jpg': [529, 357, 439, 589],\n",
       " 'frame0vid1_2_03_5.jpg': [493, 319, 418, 546],\n",
       " 'frame1vid1_2_07_1.jpg': [311, 405, 396, 573],\n",
       " 'frame0vid1_1_06_5.jpg': [527, 315, 416, 591],\n",
       " 'frame0vid1_1_06_3.jpg': [690, 316, 394, 565],\n",
       " 'frame0vid6_3_07_1.jpg': [402, 277, 484, 672],\n",
       " 'frame0vid6_1_10_1.jpg': [590, 253, 504, 636],\n",
       " 'frame0vid2_1_02_1.jpg': [727, 381, 434, 598],\n",
       " 'frame0vid1_1_06_4.jpg': [610, 310, 407, 586],\n",
       " 'frame0vid2_3_05_2.jpg': [387, 312, 429, 560],\n",
       " 'frame0vid1_3_05_4.jpg': [355, 317, 433, 570],\n",
       " 'frame0vid2_2_04_2.jpg': [340, 233, 474, 647],\n",
       " 'frame0vid3_2_10_1.jpg': [238, 306, 542, 711],\n",
       " 'frame0vid5_2_06_1.jpg': [356, 397, 356, 532],\n",
       " 'frame1vid1_2_08_1.jpg': [188, 364, 390, 546],\n",
       " 'frame0vid2_3_06_4.jpg': [223, 358, 404, 581],\n",
       " 'frame0vid4_2_09_1.jpg': [294, 361, 400, 501],\n",
       " 'frame0vid1_3_04_1.jpg': [418, 355, 379, 526],\n",
       " 'frame0vid4_2_08_1.jpg': [292, 392, 355, 487],\n",
       " 'frame0vid3_3_04_1.jpg': [579, 333, 504, 672],\n",
       " 'frame0vid2_2_04_5.jpg': [300, 248, 449, 626],\n",
       " 'frame0vid5_1_06_1.jpg': [515, 415, 326, 475],\n",
       " 'frame0vid2_3_09_1.jpg': [341, 318, 448, 605],\n",
       " 'frame0vid4_2_03_1.jpg': [261, 351, 402, 572],\n",
       " 'frame0vid2_2_03_3.jpg': [744, 359, 411, 556],\n",
       " 'frame0vid2_2_08_1.jpg': [202, 352, 359, 510],\n",
       " 'frame0vid4_1_08_1.jpg': [679, 356, 419, 574],\n",
       " 'frame0vid2_2_07_1.jpg': [342, 333, 396, 571],\n",
       " 'frame0vid3_3_08_1.jpg': [316, 361, 514, 741],\n",
       " 'frame0vid4_1_04_1.jpg': [395, 288, 520, 719],\n",
       " 'frame0vid4_3_07_1.jpg': [482, 329, 381, 516],\n",
       " 'frame0vid2_1_06_1.jpg': [545, 373, 312, 462],\n",
       " 'frame0vid2_1_03_1.jpg': [615, 342, 379, 539],\n",
       " 'frame0vid1_1_07_3.jpg': [715, 303, 462, 625],\n",
       " 'frame0vid2_3_03_5.jpg': [571, 396, 356, 478],\n",
       " 'frame0vid5_1_08_1.jpg': [739, 377, 366, 501],\n",
       " 'frame0vid4_2_07_1.jpg': [402, 358, 391, 528],\n",
       " 'frame0vid1_3_02_4.jpg': [518, 307, 438, 572],\n",
       " 'frame0vid2_2_06_4.jpg': [444, 266, 390, 572],\n",
       " 'frame0vid2_1_09_1.jpg': [695, 364, 419, 552],\n",
       " 'frame0vid1_2_02_3.jpg': [381, 283, 384, 488],\n",
       " 'frame0vid2_3_07_4.jpg': [373, 405, 349, 488],\n",
       " 'frame0vid4_2_10_1.jpg': [299, 343, 435, 588],\n",
       " 'frame0vid2_2_09_1.jpg': [250, 387, 365, 483],\n",
       " 'frame4vid2_1_05_1.jpg': [600, 353, 400, 510],\n",
       " 'frame0vid1_2_02_2.jpg': [446, 314, 386, 510],\n",
       " 'frame0vid2_3_06_3.jpg': [304, 398, 408, 621],\n",
       " 'frame0vid4_3_08_1.jpg': [363, 304, 392, 563],\n",
       " 'frame1vid1_3_09_1.jpg': [228, 337, 414, 556],\n",
       " 'frame4vid1_3_05_1.jpg': [359, 374, 390, 524],\n",
       " 'frame0vid2_2_03_5.jpg': [587, 311, 391, 510],\n",
       " 'frame0vid1_1_03_1.jpg': [603, 334, 428, 612],\n",
       " 'frame0vid1_2_06_1.jpg': [384, 407, 359, 533],\n",
       " 'frame0vid1_2_05_4.jpg': [219, 189, 446, 555],\n",
       " 'frame0vid1_2_09_1.jpg': [215, 363, 379, 516],\n",
       " 'frame0vid2_3_04_4.jpg': [240, 342, 421, 577],\n",
       " 'frame0vid2_3_10_1.jpg': [377, 317, 423, 539],\n",
       " 'frame0vid4_2_04_1.jpg': [397, 367, 380, 528],\n",
       " 'frame0vid5_1_10_1.jpg': [626, 333, 461, 590],\n",
       " 'frame0vid3_3_03_3.jpg': [624, 391, 386, 533],\n",
       " 'frame0vid2_2_06_5.jpg': [440, 260, 388, 569],\n",
       " 'frame0vid1_1_06_1.jpg': [484, 429, 318, 461],\n",
       " 'frame0vid1_3_08_5.jpg': [231, 332, 440, 631],\n",
       " 'frame0vid2_3_05_3.jpg': [387, 344, 444, 591],\n",
       " 'frame0vid1_3_08_1.jpg': [302, 390, 355, 528],\n",
       " 'frame0vid2_2_07_5.jpg': [245, 263, 420, 592],\n",
       " 'frame0vid4_3_04_1.jpg': [475, 413, 390, 519],\n",
       " 'frame0vid4_2_06_1.jpg': [364, 375, 351, 498],\n",
       " 'frame0vid1_2_04_4.jpg': [198, 184, 496, 679],\n",
       " 'frame0vid6_2_07_1.jpg': [294, 318, 471, 666],\n",
       " 'frame0vid2_3_07_3.jpg': [403, 363, 389, 544],\n",
       " 'frame0vid2_1_04_1.jpg': [434, 378, 411, 590],\n",
       " 'frame0vid2_3_08_5.jpg': [318, 310, 423, 607],\n",
       " 'frame0vid2_2_07_2.jpg': [211, 334, 474, 688],\n",
       " 'frame0vid2_3_05_4.jpg': [338, 327, 422, 561],\n",
       " 'frame0vid1_1_04_3.jpg': [628, 239, 500, 654],\n",
       " 'frame0vid1_1_07_2.jpg': [756, 294, 524, 681],\n",
       " 'frame0vid2_1_07_1.jpg': [819, 348, 406, 562],\n",
       " 'frame0vid1_1_04_4.jpg': [571, 297, 483, 646],\n",
       " 'frame0vid3_1_06_4.jpg': [522, 309, 409, 595],\n",
       " 'frame0vid1_1_03_3.jpg': [795, 291, 416, 541],\n",
       " 'frame0vid4_1_09_1.jpg': [752, 325, 495, 641],\n",
       " 'frame0vid1_1_02_1.jpg': [667, 353, 421, 562],\n",
       " 'frame0vid1_1_02_4.jpg': [512, 296, 456, 568],\n",
       " 'frame0vid2_3_04_5.jpg': [280, 332, 403, 530],\n",
       " 'frame0vid1_3_10_1.jpg': [529, 376, 388, 488],\n",
       " 'frame0vid2_2_04_3.jpg': [312, 287, 494, 675],\n",
       " 'frame0vid2_2_06_3.jpg': [300, 369, 392, 593],\n",
       " 'frame0vid1_2_04_1.jpg': [314, 324, 405, 573],\n",
       " 'frame0vid1_1_02_5.jpg': [420, 301, 455, 568],\n",
       " 'frame1vid1_1_08_1.jpg': [750, 374, 346, 465],\n",
       " 'frame0vid1_1_05_3.jpg': [664, 243, 495, 618],\n",
       " 'frame0vid4_1_03_1.jpg': [578, 304, 481, 689],\n",
       " 'frame3vid5_1_05_1.jpg': [728, 319, 376, 487]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeldar/anaconda3/envs/ss/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/yeldar/anaconda3/envs/ss/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from networks import get_model\n",
    "from datasets import data_merge\n",
    "from optimizers import get_optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import *\n",
    "from utils import *\n",
    "from configs import parse_args\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from loss import *\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(16)\n",
    "np.random.seed(16)\n",
    "random.seed(16)\n",
    "\n",
    "data_dir = \"/home/yeldar/Documents/Liveness/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bank = data_merge(data_dir)\n",
    "# train_set = data_bank.get_datasets(train=True, protocol='Custom', img_size=256, map_size=256, transform=transformer_train_pure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=4)\n",
    "max_iter = 120*len(train_loader)\n",
    "for i, sample_batched in enumerate(train_loader):\n",
    "    image_x, label, UUID = sample_batched[\"image_x\"].cuda(), sample_batched[\"label\"].cuda(), sample_batched[\"UUID\"].cuda()\n",
    "    print(image_x.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZAHODIT V TEST\n",
      "Loading Custom, number: 104\n",
      "Total number: 104\n",
      "[1/1]Testing Custom...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n",
      "torch.Size([8, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "test_data_dic = data_bank.get_datasets(train=False, protocol='Custom', img_size=256, transform=transformer_test_video())\n",
    "test_set = test_data_dic['Custom']\n",
    "\n",
    "map_score_name_list = []\n",
    "for i, test_name in enumerate(test_data_dic.keys()):\n",
    "    print(\"[{}/{}]Testing {}...\".format(i+1, len(test_data_dic), test_name))\n",
    "    test_set = test_data_dic[test_name]\n",
    "    test_loader = DataLoader(test_set, batch_size=8, shuffle=False, num_workers=4)\n",
    "    # with torch.no_grad():\n",
    "    #     start_time = time.time()\n",
    "    #     scores_list = []\n",
    "    for i, sample_batched in enumerate(test_loader):\n",
    "        image_x, label, map_x = sample_batched[\"image_x\"].cuda(), sample_batched[\"label\"].cuda(), sample_batched[\"map_x\"].cuda()\n",
    "        print(image_x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0939, 0.4450, 0.0898, 0.0556, 0.2304, 0.2806, 0.4860, 0.1372],\n",
      "\n",
      "0.0939\n",
      "0.445\n",
      "0.0898\n",
      "0.0556\n",
      "0.2304\n",
      "0.2806\n",
      "0.486\n",
      "0.1372\n",
      "       device='cuda:0') tensor([[0],\n",
      "\n",
      "0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/yeldar/Documents/Liveness/SSAN/Untitled.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/Untitled.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/Untitled.ipynb#X30sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/Untitled.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(tokens[\u001b[39m1\u001b[39;49m])  \u001b[39m# int(tokens[1])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/Untitled.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m val_scores\u001b[39m.\u001b[39mappend(score)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/Untitled.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m val_labels\u001b[39m.\u001b[39mappend(label)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "map_score_val_filename = \"/home/yeldar/Documents/Liveness/SSAN/results/demo/score/epoch_1/Custom_score.txt\"\n",
    "with open(map_score_val_filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "val_scores = []\n",
    "val_labels = []\n",
    "data = []\n",
    "count = 0.0\n",
    "num_real = 0.0\n",
    "num_fake = 0.0\n",
    "for line in lines:\n",
    "    # try:\n",
    "    print(line)\n",
    "    scores = []\n",
    "    tokens = line.split(',')\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            count += 1\n",
    "            if 'tensor' in token:\n",
    "                score = token.split('[')[-1]\n",
    "            else:\n",
    "                score = token.replace(' ', '')\n",
    "            score = score.replace(']', '')\n",
    "            score = float(score)\n",
    "            print(score)\n",
    "            scores.append(score)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    label = float(tokens[1])  # int(tokens[1])\n",
    "    val_scores.append(score)\n",
    "    val_labels.append(label)\n",
    "    data.append({'map_score': score, 'label': label})\n",
    "    if label==1:\n",
    "        num_real += 1\n",
    "    else:\n",
    "        num_fake += 1\n",
    "    # except:\n",
    "    #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0939\n",
      "0.445\n",
      "0.0898\n",
      "0.0556\n",
      "0.2304\n",
      "0.2806\n",
      "0.486\n",
      "0.1372\n"
     ]
    }
   ],
   "source": [
    "ass = \"tensor([0.0939, 0.4450, 0.0898, 0.0556, 0.2304, 0.2806, 0.4860, 0.1372],\"\n",
    "tokens = ass.split(',')\n",
    "for token in tokens:\n",
    "    try:\n",
    "        if 'tensor' in token:\n",
    "            score = token.split('[')[-1]\n",
    "        else:\n",
    "            score = token.replace(' ', '')\n",
    "        score = score.replace(']', '')\n",
    "        score = float(score)\n",
    "        print(score)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0939\n",
      "2\n",
      "0.2169\n",
      "4\n",
      "0.0973\n",
      "6\n",
      "0.0796\n",
      "8\n",
      "0.0722\n",
      "10\n",
      "0.3973\n",
      "12\n",
      "0.1268\n",
      "14\n",
      "0.9609\n",
      "16\n",
      "0.9018\n",
      "18\n",
      "0.4668\n",
      "20\n",
      "0.9538\n",
      "22\n",
      "0.1427\n",
      "24\n",
      "0.9161\n"
     ]
    }
   ],
   "source": [
    "# Extracting tensors using regex\n",
    "import re\n",
    "\n",
    "file=open(map_score_val_filename,\"r\")\n",
    "\n",
    "data = file.read()\n",
    "\n",
    "tensor_pattern = r'tensor\\(([^)]+)\\)'\n",
    "cuda_pattern = r'cuda:\\d+'\n",
    "matches_tensor = re.findall(tensor_pattern, data)\n",
    "matches_cuda = re.findall(cuda_pattern, data)\n",
    "\n",
    "tensors = []\n",
    "for i in range(0, len(matches_tensor), 2):\n",
    "    tensor_values = list(map(float, re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", matches_tensor[i])))\n",
    "    cuda_device = matches_cuda[i].split('=')[-1].strip(\"'\")\n",
    "    tensor = {\n",
    "        'values': tensor_values,\n",
    "        'device': cuda_device\n",
    "    }\n",
    "    tensors.append(tensor)\n",
    "    print(i)\n",
    "    print(tensor_values[0])\n",
    "    # print(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
