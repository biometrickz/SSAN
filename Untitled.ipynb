{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets preparation. 1. Creating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6680d6e1-d4a3-45da-b138-252c1803b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50f6d12-156a-44c7-b2a7-7664e393588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels_csv(dirr):\n",
    "    train_files = os.listdir(dirr)\n",
    "    df = pd.DataFrame(columns=[\"label\", \"fname\"])\n",
    "    df[\"fname\"] = train_files\n",
    "    if 'mask' in dirr:\n",
    "        df[\"label\"] = 1\n",
    "    else:\n",
    "        df[\"label\"] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf664bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              fname\n",
      "0      0  frameNr_105_Samsung _0001e96803--6288c7db559b2...\n",
      "1      0           a4ad4dfa-2574-40b7-971c-e009285e9c71.jpg\n",
      "2      0           cfa95dab-95a5-453f-bf9c-db7ff1ecb938.jpg\n",
      "3      0           d6c8fa5b-604c-4363-a7bb-645c2dfc9abc.jpg\n",
      "4      0  vid_11031_frameNr_113_Xiaomi _0001e96803--6266...\n",
      "   label                                              fname\n",
      "0      1  frame#_541_CFX Sin of Pride (Djinn variant) Si...\n",
      "1      1                     3D-AdultDoll_000071_005308.jpg\n",
      "2      1                 images - 2023-09-25T130134.154.jpg\n",
      "3      1                     3D-AdultDoll_000071_005987.jpg\n",
      "4      1                     3D-AdultDoll_000071_005624.jpg\n",
      "   label                                              fname\n",
      "0      0  vid_6599_frameNr_105_Zte blade_0001e96803--624...\n",
      "1      0                             live_053121_000003.jpg\n",
      "2      0                             live_053489_000001.jpg\n",
      "3      0                             live_056331_000005.jpg\n",
      "4      0  frameNr_113_Poco X3 pro_0001e96803--62add2aff7...\n",
      "   label                           fname\n",
      "0      1       frameNr_3_mask_12.mp4.jpg\n",
      "1      1       3D-Mask_000132_000001.jpg\n",
      "2      1    frameNr_3_outline_12.mp4.jpg\n",
      "3      1  3D-AdultDoll_000046_000001.jpg\n",
      "4      1   frameNr_19_outline_12.mp4.jpg\n",
      "   label                                              fname\n",
      "0      0           9ce607d7-5937-4627-9d81-e677ad55ea4a.jpg\n",
      "1      0                             live_002273_000002.jpg\n",
      "2      0  vid_2746_frameNr_113_Tecno pop2_0001e96803--62...\n",
      "3      0  vid_1259_frameNr_137_Samsung Galaxy S7_0001e96...\n",
      "4      0           8c9d036e-9bc8-474a-8c1e-2fbca574ad3b.jpg\n",
      "   label                           fname\n",
      "0      1               2dmask_299_02.png\n",
      "1      1  3D-GarageKit_000418_000001.jpg\n",
      "2      1     frameNr_19_latex_10.mp4.jpg\n",
      "3      1               2dmask_433_05.png\n",
      "4      1               2dmask_314_01.png\n"
     ]
    }
   ],
   "source": [
    "dir_p = f\"/mnt/8TB/ml_projects_yeldar/PATCHNET_DATASET\"\n",
    "for tp in ['train', 'test', 'val']:\n",
    "    for cp in ['live', 'mask']:\n",
    "        dirr = f\"{dir_p}/{tp}/{cp}\"\n",
    "        df = generate_labels_csv(dirr)\n",
    "        print(df.head())\n",
    "        df.to_csv(os.path.join(dirr, f\"{tp}_list.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014309c0-9800-42e5-849b-5e5ce36af310",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 0\n",
    "for ds in ['0.0_padded_liveness_dataset', 'insigtface_cropped_fas_faces', 'JOINED_DATASET/JOINED_DATASET']:\n",
    "    for tp in ['train', 'test', 'val']:\n",
    "        tmp = tp\n",
    "        if (tp == 'train'):\n",
    "            n_rows = 50000\n",
    "        else:\n",
    "            n_rows = 5000\n",
    "        if (ds =='insigtface_cropped_fas_faces'):\n",
    "            if (tp == 'train'):\n",
    "                for l in ['live', 'spoof']:\n",
    "                    dirr1 = f\"/media/user/6TB1/{ds}/{l}\"\n",
    "                    df = generate_labels_csv(dirr1)[:n_rows]\n",
    "                    df.to_csv(os.path.join(dirr1, f\"{tp}_list.csv\"), index=False)\n",
    "                    print(ds, tp, len(df))\n",
    "            continue\n",
    "        elif (ds =='0.0_padded_liveness_dataset'):\n",
    "            if (tp != 'test'):\n",
    "                tp = tp + '/1_300x300'\n",
    "        for l in ['live', 'spoof']:\n",
    "            dirr1 = f\"/media/user/6TB1/{ds}/{tp}/{l}\"\n",
    "            # dirr2 = \"/home/yeldar/Documents/Liveness/datasets/sample_dataset/Custom/insight/train/spoof\"\n",
    "            # df = pd.concat([generate_labels_csv(dirr1), generate_labels_csv(dirr2)])\n",
    "            # if \n",
    "            df = generate_labels_csv(dirr1)[:n_rows]\n",
    "            df.to_csv(os.path.join(dirr1, f\"{tmp}_list.csv\"), index=False)\n",
    "            print(ds, tp, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "info_list = '/home/yeldar/Documents/Liveness/datasets/sample_dataset/Custom/insight/train/live/train_list.csv'\n",
    "df = pd.read_csv(info_list, delimiter=\",\", header=None).drop([0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merging live and spoof images into one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_folders(dir1, dir2, dest):\n",
    "    for fl in os.listdir(dir1):\n",
    "        cur_p = os.path.join(dir1, fl)\n",
    "        dst_p = os.path.join(dest, fl)\n",
    "        os.rename(cur_p, dst_p)\n",
    "    for fl2 in os.listdir(dir2):\n",
    "        cur_p = os.path.join(dir2, fl2)\n",
    "        dst_p = os.path.join(dest, fl2)\n",
    "        os.rename(cur_p, dst_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirr1 = \"/home/yeldar/Documents/adds-depthnet/padded2/test/live\"\n",
    "dirr2 = \"/home/yeldar/Documents/adds-depthnet/padded2/test/spoof\"\n",
    "dest = \"/home/yeldar/Documents/adds-depthnet/padded2/Test_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_folders(dirr1, dirr2, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8959c",
   "metadata": {},
   "source": [
    "## Testing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import data_merge\n",
    "from transformers import *\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from networks import get_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84aa59f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PATCHNET, number: 2000\n",
      "Total number: 2000\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/mnt/8TB/ml_projects_yeldar/\"\n",
    "data_bank = data_merge(data_dir)\n",
    "protocol = \"Patchnet\"\n",
    "img_size = 256\n",
    "map_size = 32\n",
    "batch_size = 16\n",
    "num_workers = 8\n",
    "num_epochs = 10\n",
    "model_type = 'SSAN_M'\n",
    "# define model\n",
    "train_set = data_bank.get_datasets(train=True, protocol=protocol, img_size=img_size, map_size=map_size, transform=transformer_train())\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "max_iter = num_epochs*len(train_loader)\n",
    "model = get_model(model_type, max_iter).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715e05ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PATCHNET, number: 1878\n",
      "Total number: 1878\n",
      "[1/1]Testing PATCHNET...\n"
     ]
    }
   ],
   "source": [
    "test_data_dic = data_bank.get_datasets(train=False, protocol=protocol, img_size=img_size, transform=transformer_custom())\n",
    "test_loader = None\n",
    "for i, test_name in enumerate(test_data_dic.keys()):\n",
    "    print(\"[{}/{}]Testing {}...\".format(i+1, len(test_data_dic), test_name))\n",
    "    test_set = test_data_dic[test_name]\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6565da93",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 243, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"/home/user/ml_projects/Yeldar/SSAN/datasets/Load_Custom.py\", line 30, in __getitem__\n    sample = self.transform(sample)\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/home/user/ml_projects/Yeldar/SSAN/transformers/transformer_test.py\", line 50, in __call__\n    image_x = image_x[:,:,:,::-1].transpose((0, 3, 1, 2))\nIndexError: too many indices for array: array is 3-dimensional, but 4 were indexed\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, sample_batched \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[1;32m      5\u001b[0m         image_x, label, map_x \u001b[38;5;241m=\u001b[39m sample_batched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_x\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(), sample_batched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(), sample_batched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap_x\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEY\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ss/lib/python3.8/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 243, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"/home/user/ml_projects/Yeldar/SSAN/datasets/Load_Custom.py\", line 30, in __getitem__\n    sample = self.transform(sample)\n  File \"/home/user/anaconda3/envs/ss/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/home/user/ml_projects/Yeldar/SSAN/transformers/transformer_test.py\", line 50, in __call__\n    image_x = image_x[:,:,:,::-1].transpose((0, 3, 1, 2))\nIndexError: too many indices for array: array is 3-dimensional, but 4 were indexed\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = []\n",
    "    for i, sample_batched in enumerate(test_loader):\n",
    "        image_x, label, map_x = sample_batched[\"image_x\"].cuda(), sample_batched[\"label\"].cuda(), sample_batched[\"map_x\"].cuda()\n",
    "        print(\"HEY\", image_x.shape)\n",
    "        map_score = 0\n",
    "        for frame_i in range(image_x.shape[1]):\n",
    "            pred_map, fea_x1_x1, fea_x1_x2, _ = model(image_x[:,frame_i,:,:,:], image_x[:,frame_i,:,:,:])\n",
    "            score_norm = torch.sum(pred_map, dim=(1, 2))/(map_size*map_size)\n",
    "        map_score += score_norm\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
