{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpacking Nurma's dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6680d6e1-d4a3-45da-b138-252c1803b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50f6d12-156a-44c7-b2a7-7664e393588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_csv(dirr):\n",
    "    train_files = os.listdir(dirr)\n",
    "    df = pd.DataFrame(columns=[\"label\", \"fname\"])\n",
    "    df[\"fname\"] = train_files\n",
    "    if 'live' in dirr:\n",
    "        df[\"label\"] = 0\n",
    "    else:\n",
    "        df[\"label\"] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "014309c0-9800-42e5-849b-5e5ce36af310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirr1 = \"train/live\"\n",
    "dirr2 = \"train/spoof\"\n",
    "df = pd.concat([gen_csv(dirr1), gen_csv(dirr2)])\n",
    "df.to_csv(\"train_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28be4f4a-f662-4213-80f0-d1773bb561c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0      frame0vid3_3_09_1.jpg\n",
       "1      frame4vid2_2_05_1.jpg\n",
       "2      frame0vid3_3_10_1.jpg\n",
       "3      frame0vid3_2_10_1.jpg\n",
       "4      frame0vid2_3_06_1.jpg\n",
       "               ...          \n",
       "106    frame0vid1_3_02_4.jpg\n",
       "107    frame0vid1_2_02_4.jpg\n",
       "108    frame0vid1_2_02_5.jpg\n",
       "109    frame0vid1_3_02_5.jpg\n",
       "110    frame0vid1_2_04_3.jpg\n",
       "Name: fname, Length: 225, dtype: object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fname'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_info(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.root_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid3_3_09_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>frame4vid2_2_05_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid3_3_10_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid3_2_10_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>frame0vid2_3_06_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_3_02_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_2_02_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_2_02_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_3_02_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1</td>\n",
       "      <td>frame0vid1_2_04_3.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1                      2\n",
       "0    0  frame0vid3_3_09_1.jpg\n",
       "1    0  frame4vid2_2_05_1.jpg\n",
       "2    0  frame0vid3_3_10_1.jpg\n",
       "3    0  frame0vid3_2_10_1.jpg\n",
       "4    0  frame0vid2_3_06_1.jpg\n",
       "..  ..                    ...\n",
       "220  1  frame0vid1_3_02_4.jpg\n",
       "221  1  frame0vid1_2_02_4.jpg\n",
       "222  1  frame0vid1_2_02_5.jpg\n",
       "223  1  frame0vid1_3_02_5.jpg\n",
       "224  1  frame0vid1_2_04_3.jpg\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = \"/home/yeldar/Documents/Liveness/datasets/\"\n",
    "CUSTOM_Train = dataset_info()\n",
    "CUSTOM_Train.root_dir = os.path.join(image_dir, \"sample_dataset\")\n",
    "data_dir = CUSTOM_Train.root_dir\n",
    "root_dir = os.path.join(data_dir, \"Train_files\")\n",
    "info_list = os.path.join(data_dir, \"train_list.csv\")\n",
    "labels = pd.read_csv(info_list, delimiter=\",\", header=None).drop([0], axis=1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from scrfd.scrfd import SCRFD \n",
    "import warnings \n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== SCRFD-500m onnx Face Detector loaded. ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeldar/anaconda3/envs/dot/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:53: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\"Specified provider '{}' is not in available provider names.\"\n"
     ]
    }
   ],
   "source": [
    "face_detector = SCRFD(model_file='./scrfd/scrfd_500m_bnkps.onnx')\n",
    "face_detector.prepare(1)\n",
    "print(\"====== SCRFD-500m onnx Face Detector loaded. ======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_face_detection(image, face_detector):\n",
    "    \n",
    "    bboxes, kpss = face_detector.detect(image, input_size=(640, 640))\n",
    "    bboxes_b = bboxes[:, 0:4]\n",
    "    bboxes_b = bboxes_b.astype('int32')\n",
    "    #  postprocess bounding boxes\n",
    "    x, y, w, h = [[box[0], box[1], box[2] - box[0], box[3] - box[1]]  for box in bboxes_b][0]\n",
    "    # face = image[y:y+h, x:x+w]\n",
    "    return x, y, w, h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame0vid5_3_10_1.jpg\n",
      "frame0vid1_2_02_1.jpg\n",
      "frame0vid1_3_06_4.jpg\n",
      "frame0vid1_1_04_2.jpg\n",
      "frame0vid1_3_02_1.jpg\n",
      "frame0vid1_1_07_4.jpg\n",
      "frame0vid1_3_09_1.jpg\n",
      "frame0vid1_2_05_5.jpg\n",
      "frame0vid3_1_06_2.jpg\n",
      "frame0vid1_1_05_4.jpg\n",
      "frame0vid5_1_09_1.jpg\n",
      "frame1vid1_3_10_1.jpg\n",
      "frame0vid2_3_04_2.jpg\n",
      "frame0vid1_2_07_3.jpg\n",
      "frame0vid1_2_06_3.jpg\n",
      "frame0vid2_2_06_1.jpg\n",
      "frame3vid5_3_05_1.jpg\n",
      "frame0vid2_3_03_4.jpg\n",
      "frame0vid1_2_02_5.jpg\n",
      "frame1vid1_2_09_1.jpg\n",
      "frame0vid3_3_03_2.jpg\n",
      "frame0vid3_3_09_1.jpg\n",
      "frame0vid6_2_09_1.jpg\n",
      "frame0vid1_2_03_1.jpg\n",
      "frame0vid2_3_05_5.jpg\n",
      "frame0vid4_3_06_1.jpg\n",
      "frame4vid1_1_05_1.jpg\n",
      "frame0vid1_2_08_1.jpg\n",
      "frame0vid1_3_06_1.jpg\n",
      "frame0vid1_3_06_3.jpg\n",
      "frame0vid2_2_05_2.jpg\n",
      "frame0vid1_3_06_2.jpg\n",
      "frame0vid3_1_10_1.jpg\n",
      "frame0vid2_2_03_2.jpg\n",
      "frame0vid3_1_08_4.jpg\n",
      "frame0vid2_2_07_4.jpg\n",
      "frame0vid1_1_05_5.jpg\n",
      "frame0vid1_2_04_2.jpg\n",
      "frame1vid2_1_10_1.jpg\n",
      "frame1vid1_3_07_1.jpg\n",
      "frame4vid2_2_05_1.jpg\n",
      "frame0vid4_1_10_1.jpg\n",
      "frame0vid1_2_08_5.jpg\n",
      "frame0vid2_3_04_3.jpg\n",
      "frame0vid5_2_09_1.jpg\n",
      "frame0vid4_3_03_1.jpg\n",
      "frame0vid1_2_05_3.jpg\n",
      "frame0vid1_1_02_2.jpg\n",
      "frame0vid6_2_08_1.jpg\n",
      "frame0vid4_1_06_1.jpg\n",
      "frame0vid1_2_06_5.jpg\n",
      "frame0vid3_3_06_1.jpg\n",
      "frame0vid1_1_06_2.jpg\n",
      "frame0vid1_2_08_4.jpg\n",
      "frame0vid3_1_08_5.jpg\n",
      "frame0vid2_1_08_1.jpg\n",
      "frame3vid4_2_05_1.jpg\n",
      "frame0vid1_1_08_1.jpg\n",
      "frame0vid1_1_07_1.jpg\n",
      "frame0vid5_1_07_1.jpg\n",
      "frame0vid3_3_10_1.jpg\n",
      "frame0vid2_3_07_2.jpg\n",
      "frame0vid2_2_06_2.jpg\n",
      "frame0vid6_3_08_1.jpg\n",
      "frame1vid2_1_09_1.jpg\n",
      "frame0vid3_1_04_2.jpg\n",
      "frame0vid3_3_07_1.jpg\n",
      "frame0vid3_3_03_1.jpg\n",
      "frame0vid1_2_10_1.jpg\n",
      "frame3vid4_3_05_1.jpg\n",
      "frame0vid1_2_07_1.jpg\n",
      "frame0vid1_1_08_4.jpg\n",
      "frame0vid2_2_08_5.jpg\n",
      "frame0vid1_2_06_2.jpg\n",
      "frame4vid1_2_05_1.jpg\n",
      "frame0vid1_1_03_5.jpg\n",
      "frame0vid1_2_07_5.jpg\n",
      "frame0vid2_3_02_1.jpg\n",
      "frame0vid2_3_06_5.jpg\n",
      "frame0vid2_2_02_1.jpg\n",
      "frame0vid1_3_04_2.jpg\n",
      "frame0vid2_2_04_4.jpg\n",
      "frame0vid2_3_07_5.jpg\n",
      "frame0vid5_3_09_1.jpg\n",
      "frame3vid5_2_05_1.jpg\n",
      "frame0vid2_2_08_4.jpg\n",
      "frame0vid4_1_07_1.jpg\n",
      "frame0vid1_1_10_1.jpg\n",
      "frame0vid1_2_02_4.jpg\n",
      "depth\n",
      "frame0vid1_3_08_4.jpg\n",
      "frame0vid1_2_07_4.jpg\n",
      "frame0vid1_1_05_2.jpg\n",
      "frame0vid3_1_09_1.jpg\n",
      "frame0vid2_2_05_3.jpg\n",
      "frame0vid4_3_09_1.jpg\n",
      "frame1vid1_1_09_1.jpg\n",
      "frame0vid2_3_06_1.jpg\n",
      "frame0vid1_3_03_1.jpg\n",
      "frame0vid1_1_08_5.jpg\n",
      "frame0vid2_3_06_2.jpg\n",
      "frame0vid2_2_05_4.jpg\n",
      "frame0vid1_2_06_4.jpg\n",
      "frame1vid2_3_10_1.jpg\n",
      "frame0vid1_3_02_5.jpg\n",
      "frame0vid1_2_05_2.jpg\n",
      "frame0vid5_2_10_1.jpg\n",
      "frame0vid1_1_02_3.jpg\n",
      "frame0vid2_2_03_4.jpg\n",
      "frame0vid1_1_09_1.jpg\n",
      "frame0vid2_2_05_5.jpg\n",
      "frame0vid3_1_06_3.jpg\n",
      "frame1vid2_2_10_1.jpg\n",
      "frame0vid1_1_03_2.jpg\n",
      "frame1vid1_1_07_1.jpg\n",
      "frame0vid1_3_07_1.jpg\n",
      "frame0vid1_1_04_5.jpg\n",
      "frame1vid1_3_08_1.jpg\n",
      "frame1vid2_2_09_1.jpg\n",
      "frame0vid6_3_09_1.jpg\n",
      "frame0vid1_1_07_5.jpg\n",
      "frame0vid1_2_04_5.jpg\n",
      "frame0vid1_2_03_4.jpg\n",
      "frame0vid1_1_04_1.jpg\n",
      "frame0vid2_3_08_4.jpg\n",
      "frame0vid2_2_03_1.jpg\n",
      "frame0vid2_2_07_3.jpg\n",
      "frame0vid1_1_03_4.jpg\n",
      "frame0vid3_1_05_4.jpg\n",
      "frame0vid1_2_07_2.jpg\n",
      "frame0vid5_1_03_1.jpg\n",
      "frame0vid1_2_04_3.jpg\n",
      "frame0vid1_3_02_2.jpg\n",
      "frame0vid1_2_03_5.jpg\n",
      "frame1vid1_2_07_1.jpg\n",
      "frame0vid1_1_06_5.jpg\n",
      "frame0vid1_1_06_3.jpg\n",
      "frame0vid6_3_07_1.jpg\n",
      "frame0vid6_1_10_1.jpg\n",
      "frame0vid2_1_02_1.jpg\n",
      "frame0vid1_1_06_4.jpg\n",
      "frame0vid2_3_05_2.jpg\n",
      "frame0vid1_3_05_4.jpg\n",
      "frame0vid2_2_04_2.jpg\n",
      "frame0vid3_2_10_1.jpg\n",
      "frame0vid5_2_06_1.jpg\n",
      "frame1vid1_2_08_1.jpg\n",
      "frame0vid2_3_06_4.jpg\n",
      "frame0vid4_2_09_1.jpg\n",
      "frame0vid1_3_04_1.jpg\n",
      "frame0vid4_2_08_1.jpg\n",
      "frame0vid3_3_04_1.jpg\n",
      "frame0vid2_2_04_5.jpg\n",
      "frame0vid5_1_06_1.jpg\n",
      "frame0vid2_3_09_1.jpg\n",
      "frame0vid4_2_03_1.jpg\n",
      "frame0vid2_2_03_3.jpg\n",
      "frame0vid2_2_08_1.jpg\n",
      "frame0vid4_1_08_1.jpg\n",
      "frame0vid2_2_07_1.jpg\n",
      "frame0vid3_3_08_1.jpg\n",
      "frame0vid4_1_04_1.jpg\n",
      "frame0vid4_3_07_1.jpg\n",
      "frame0vid2_1_06_1.jpg\n",
      "frame0vid2_1_03_1.jpg\n",
      "frame0vid1_1_07_3.jpg\n",
      "frame0vid2_3_03_5.jpg\n",
      "frame0vid5_1_08_1.jpg\n",
      "frame0vid4_2_07_1.jpg\n",
      "frame0vid1_3_02_4.jpg\n",
      "frame0vid2_2_06_4.jpg\n",
      "frame0vid2_1_09_1.jpg\n",
      "frame0vid1_2_02_3.jpg\n",
      "frame0vid2_3_07_4.jpg\n",
      "frame0vid4_2_10_1.jpg\n",
      "frame0vid2_2_09_1.jpg\n",
      "frame4vid2_1_05_1.jpg\n",
      "frame0vid1_2_02_2.jpg\n",
      "frame0vid2_3_06_3.jpg\n",
      "frame0vid4_3_08_1.jpg\n",
      "frame1vid1_3_09_1.jpg\n",
      "frame4vid1_3_05_1.jpg\n",
      "frame0vid2_2_03_5.jpg\n",
      "frame0vid1_1_03_1.jpg\n",
      "frame0vid1_2_06_1.jpg\n",
      "frame0vid1_2_05_4.jpg\n",
      "frame0vid1_2_09_1.jpg\n",
      "frame0vid2_3_04_4.jpg\n",
      "frame0vid2_3_10_1.jpg\n",
      "frame0vid4_2_04_1.jpg\n",
      "frame0vid5_1_10_1.jpg\n",
      "frame0vid3_3_03_3.jpg\n",
      "frame0vid2_2_06_5.jpg\n",
      "frame0vid1_1_06_1.jpg\n",
      "frame0vid1_3_08_5.jpg\n",
      "frame0vid2_3_05_3.jpg\n",
      "frame0vid1_3_08_1.jpg\n",
      "frame0vid2_2_07_5.jpg\n",
      "frame0vid4_3_04_1.jpg\n",
      "frame0vid4_2_06_1.jpg\n",
      "frame0vid1_2_04_4.jpg\n",
      "frame0vid6_2_07_1.jpg\n",
      "frame0vid2_3_07_3.jpg\n",
      "frame0vid2_1_04_1.jpg\n",
      "frame0vid2_3_08_5.jpg\n",
      "frame0vid2_2_07_2.jpg\n",
      "frame0vid2_3_05_4.jpg\n",
      "frame0vid1_1_04_3.jpg\n",
      "frame0vid1_1_07_2.jpg\n",
      "frame0vid2_1_07_1.jpg\n",
      "frame0vid1_1_04_4.jpg\n",
      "frame0vid3_1_06_4.jpg\n",
      "frame0vid1_1_03_3.jpg\n",
      "frame0vid4_1_09_1.jpg\n",
      "frame0vid1_1_02_1.jpg\n",
      "frame0vid1_1_02_4.jpg\n",
      "frame0vid2_3_04_5.jpg\n",
      "frame0vid1_3_10_1.jpg\n",
      "frame0vid2_2_04_3.jpg\n",
      "frame0vid2_2_06_3.jpg\n",
      "frame0vid1_2_04_1.jpg\n",
      "frame0vid1_1_02_5.jpg\n",
      "frame1vid1_1_08_1.jpg\n",
      "frame0vid1_1_05_3.jpg\n",
      "frame0vid4_1_03_1.jpg\n",
      "frame3vid5_1_05_1.jpg\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"/home/yeldar/Documents/Liveness/datasets/sample_dataset/Train_files/\"\n",
    "for img_n in os.listdir(img_dir):\n",
    "    img_path = os.path.join(img_dir, img_n)\n",
    "     x, y, w, h = get_bbox_face_detection(img_path, face_detector)\n",
    "        image_x = cv2.resize(crop_face_from_scene(image_x_temp, [y, x, w, h], face_scale), (self.img_size, self.img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Train.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yeldar/Documents/Liveness/SSAN/datasets/Untitled.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/datasets/Untitled.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/datasets/Untitled.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/yeldar/Documents/Liveness/datasets/sample_dataset/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/datasets/Untitled.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mTrain.pickle\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yeldar/Documents/Liveness/SSAN/datasets/Untitled.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     bboxes \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(handle)\n",
      "File \u001b[0;32m~/anaconda3/envs/dot/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Train.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "img_dir = \"/home/yeldar/Documents/Liveness/datasets/sample_dataset/\"\n",
    "f_path = os.path.join(img_dir, \"Train.pickle\")\n",
    "with open(f_path, 'rb') as handle:\n",
    "    bboxes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
