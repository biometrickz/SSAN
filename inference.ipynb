{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datasets import data_merge, data_merge_R\n",
    "from transformers import *\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from networks import get_model\n",
    "from networks import SSAN_M, SSAN_R\n",
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/mnt/8TB/ml_projects_yeldar/\"\n",
    "data_bank = data_merge_R.data_merge(data_dir)\n",
    "protocol = \"Patchnet\"\n",
    "img_size = 112\n",
    "map_size = 32\n",
    "batch_size = 256\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = './results/PatchNet/model/SSAN_R_pPatchnet_best.pth'\n",
    "model = SSAN_R().cuda()\n",
    "model.load_state_dict(torch.load(PATH)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEY PATCHNET\n",
      "Loading PATCHNET, number: 6648\n",
      "Total number: 6648\n"
     ]
    }
   ],
   "source": [
    "test_data_dic = data_bank.get_datasets(type='test', protocol=protocol, img_size=img_size, transform=transformer_test_video())\n",
    "test_loader = DataLoader(test_data_dic, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:03<00:00,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to ./test_score.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = []\n",
    "    for i, sample_batched in enumerate(tqdm(test_loader)):\n",
    "        image_x, label = sample_batched[\"image_x\"].cuda(), sample_batched[\"label\"].cuda()\n",
    "\n",
    "        cls_x1_x1, fea_x1_x1, fea_x1_x2, _ = model(image_x, image_x)\n",
    "        score_norm = torch.softmax(cls_x1_x1, dim=1)[:, 1]\n",
    "\n",
    "        for ii in range(image_x.shape[0]):\n",
    "            scores.append(\"{} {}\\n\".format(score_norm[ii], label[ii][0]))\n",
    "                    \n",
    "    map_score_val_filename = os.path.join('./', \"{}_score.txt\".format('test'))\n",
    "    print(\"score: write test scores to {}\".format(map_score_val_filename))\n",
    "    with open(map_score_val_filename, 'w') as file:\n",
    "        file.writelines(scores)\n",
    "\n",
    "    test_ACC, fpr, FRR, HTER, auc_test, test_err = performances_val(map_score_val_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9828519855595668,\n",
       " 0.018272425249169437,\n",
       " 0.016899338721528268,\n",
       " 0.017585881985348852,\n",
       " 0.9975945049687425,\n",
       " 0.018272425249169437)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ACC, fpr, FRR, HTER, auc_test, test_err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
